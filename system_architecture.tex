This section discusses Ascent's system architecture starting at its inner layer, Flow,
and moving outward to the API and actions.ke .

\subsection{Flow: A data-type agonistic data-flow based architecture}
At Ascent's core is a simple data-flow library, called Flow, that
composes and executes filters, the basic unit of execution in Ascent.
%
Flow is an evolution of a Python data-flow network
~\cite{flow_reference}, but unlike its ancestor, Flow is a C++
library.
%
Flow supports composing and executing directed acyclic graphs
(DAGs) composed of filters~\cite{LarsenAscent}.

There are three components to Flow:
\begin{itemize}
  \item \textbf{Registry}: manages the lifetime of intermediate filter results
  \item \textbf{Graph}: contains the filter graph and manages the adding of filters
  \item \textbf{Workspace}: container for both the registry and filter graph
\end{itemize}

\paragraph{Registry}
The registry is a key-value data store used to manage the intermediate
results of filters inside the data-flow network.
%
Keys within the registry are reference counted, and data contained
inside the registry is deleted when the reference counts reach zero.
%
While the data associated with a key can be a pointer to any type,
the majority of the data stored in the registry are Conduit nodes
or VTK-m data sets.

\paragraph{Graph}
The graph interface supports main operations: adding filters
and connecting filters together.
%

\paragraph{Workspace}
The workspace is a container for both the graph and the registry,
and the workspace is responsible for creating an execution for plan
for the DAG.
%
\fix{Cyrus: make sure these words are true.}
Flow uses a topological sort to ensure proper filter execution order,
tracks all intermediate results, and provides basic memory management capabilities.
%
Multiple workspaces can co-exist, and in fact, Ascent uses a Flow workspace
to evaluate expressions within the Ascent runtime.

\paragraph{Flow Filters}
Flow filters are the basic unit of execution inside of Ascent, and
almost all functionality inside of Ascent is implemented as a Flow filter.
%
Filters declare an interface, i.e., how many inputs a filter has and
if there is an output.
%
Inside Ascent, typical inputs and outputs are data sets.
%
Additionally, filters are passed a set of parameters inside of a Conduit
node.
%
Filters are registered with the workspace and can then be added to the
graph by name.


\subsection{Runtime}
The Ascent runtime exists on top of Flow and is responsible for
handling applicaiton-facing API calls and translating user-facing
``actions`` into a data-flow network.
%
Built-in functionality is registered internally with the Ascent runtime,
but externally defined filters can also be registered with Ascent,
allowing for the execution of custom code within Ascent.
%
Filters can be registers as either a ``transform'' or a ``extract''.
%
Transforms are intermediate nodes in the data-flow network and transform
data sets.
%
An example of transforms is a iso-contour, where a volume is converted
into a surface.
%
Extracts are terminal nodes in the data-flow network, and extracts
are the main mechanism for software interoperability inside of Ascent.

\subsubsection{Parallism in Ascent}
Ascent is a hybrid-parallel library, meaning that it uses both
distributed-memory(e.g., MPI) and shared-memory parallelism
(e.g., CUDA and OpenMP), and Ascent is primiary
tightly-coupled with simulations.
%
In this paradigm, simulations control how parallelism is used, so
it is imperitive that Ascent's functinality be capable of running
on the same architectures using the same types of parallism as the
simulations.
%
Ascent supports many different parallel configurations including
one MPI rank per core(i.e., no shared-memory parallism), one rank
per GPU, and one rank per node.
%
While Ascent does internally leverage shared-memory parallelism
for expressions, the majority of the shared-memory parallelism comes
from Ascent's components such as VTK-m and Devil Ray.

\paragraph{Distributed-Memory Parallelism}
Within Ascent, all MPI ranks recieve the same set of actions.
%
Since the actions are the same, all MPI ranks create and execute the same graph,
meaning
that all flow filters execute on all ranks.
%
Filter are free to use MPI and anyway they see fit, including
creating asynchronous tasks.

\paragraph{Shared-Memory Parallelism}
Ascent's main components use portable performance abstraction layers to
take advantage of the different types of shared-memory parallism on
modern supercomputers.
%
For example, VTK-m is itself a portable performance layer designed specifially
for visualization and currently supports OpenMP, CUDA, and TBB.
%
Devil Ray, while not itself a portalble performance layer, uses RAJA to execute
on different architectures, supporting OpenMP, CUDA, HIP, and TBB.

\subsection{Components built into the runtime}
Dray, python, vtkm, ADIOS, Jupyter,

\subsubsection{Data Set Representations}
Ascent uses a data abstraction, called the data object, as the input
and outputs of filters.
%
The data object is resposible for transforming data from one format
to another without unnessecary copies.
%
By using this abstraction, filters can ask for whatever data set
representation they need.
%

To support multiple data set representations, there must be a common
set of supported features, but not all data models Ascent uses
supports the same set of features.
%
Since Ascent uses Blueprint as its data interface to simulations,
all other data models must sometimes be adapted to support additional
features.
%
For example, Blueprint supports multiple topologies in the same data set
but VTK-m only supports a single topology.
%
To handle this correctly within Ascent, we wrap the data sets in a container
that treats each topology as individual VTK-m data sets.
%

\subsection{Extracts: optional python environment}
I feel like this subsection is about the ways to get to other things.
