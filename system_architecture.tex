In the previous section, we described Ascent's high level abstractions and
capabilities.
%
This section discusses Ascent's system architecture starting at its inner layer, Flow,
and moving outward.

\subsection{Flow: A data-type agonistic data-flow based architecture}
At Ascent's core is a simple data-flow library, called Flow, that
composes and executes filters, the basic unit of execution in Ascent.
%
Flow is an evolution of a Python data-flow network
~\cite{flow_reference}, but unlike its ancestor, Flow is a C++
library.
%
Flow supports composing and executing directed acyclic graphs
(DAGs) composed of filters~\cite{LarsenAscent}.

There are three components to Flow:
\begin{itemize}
  \item \textbf{Filter}: basic unit of execution
  \item \textbf{Graph}: contains the filter graph and manages the adding of filters
  \item \textbf{Registry}: manages the lifetime of intermediate filter results
  \item \textbf{Workspace}: container for both the registry and filter graph
\end{itemize}

\paragraph{Flow Filters}
Flow filters are the basic unit of execution inside of Ascent, and
almost all functionality inside of Ascent is implemented as a Flow filter.
%
Adding new capabilities to Ascent means wrapping that functionality inside
a flow filter.
%
Filters declare an interface, i.e., how many inputs a filter has and
if there is an output, and filters are passed a set of parameters inside
of a Conduit
node.
%
In terms of Ascent actions, pipeline filters are part of a chain of
data transformations and would minimally have an input
data set and an output data set, while scenes and extracts
are sinks that have an input data set and no output.
%

\paragraph{Graph}
The graph is a series of Flow filters connected together into
a DAG.
%
The graph is responsible for storing filters and connections
between filters.
%
The primary graph interface supports adding filters and connecting
filter ports(e.g., inputs and outputs) together.

\paragraph{Registry}
The registry is a key-value data store used to manage the intermediate
results of filters inside the data-flow network.
%
Keys within the registry are reference counted, and data contained
inside the registry is deleted when the reference counts reach zero.
%
While the data associated with a key can be a pointer to any type,
the majority of the data stored in the registry are Conduit nodes
or VTK-h data sets.


\paragraph{Workspace}
The workspace is a container for both the graph and the registry,
and the workspace is responsible for creating an execution for plan
for the DAG.
%
Additionally, the workspace manages the lists of known filters.
%
A filter must be registered with the workspace in order to be added to the
graph, and once registered, a filter can be added to the graph by name.
%
\fix{Cyrus: make sure these words are true.}
Flow uses a topological sort to ensure proper filter execution order,
tracks all intermediate results, and provides basic memory management capabilities.
%
Multiple workspaces can co-exist, and in fact, Ascent uses a Flow workspace
to evaluate expressions within the Ascent runtime.
%

\subsection{Runtime}
The Ascent runtime builds on top of Flow, and has two main responsibilities:
interface with the simulation and execute actions.
%
First, simulations use the runtime to configure Ascent (e.g., set MPI communicators and
exception handling options), publish their mesh data structures, set actions,
and get results out of Ascent.
%
Second, Ascent translates user-facing ``actions`` into a data-flow network that executes the requested visualization and analysis.
%

\fix{Insert something on the simulation role???}

Built-in functionality is registered internally with the Ascent runtime,
but externally defined filters can also be registered with Ascent,
allowing for the execution of custom code within Ascent.
%
The runtime Filters can be registers as either a ``transform'' or a ``extract''.
%
Transforms are intermediate nodes in the data-flow network and transform
data sets.
%
An example of transforms is a iso-contour, where a volume is converted
into a surface.
%
Extracts are terminal nodes in the data-flow network, and extracts
are the main mechanism for software interoperability inside of Ascent.

Filters enable Ascent's modular architecture.
%
To add

\subsubsection{Parallism in Ascent}
Ascent is a hybrid-parallel library, meaning that it uses both
distributed-memory(e.g., MPI) and shared-memory parallelism
(e.g., CUDA and OpenMP), and Ascent is primarily  
tightly-coupled with simulations.
%
In the tightly-coupled paradigm, simulations control how parallelism is used, so
it is imperative that Ascent's functionality be capable of running
on the same architectures using the same types of parallelism as the
simulations.
%
Ascent supports many different parallel configurations including
one MPI rank per core(i.e., no shared-memory parallelism), one rank
per GPU, and one rank per node.
%
While Ascent does internally leverage shared-memory parallelism
for expressions, the majority of the shared-memory parallelism comes
from Ascent's components such as VTK-m and Devil Ray.

\paragraph{Distributed-Memory Parallelism}
Within Ascent, all MPI ranks receive the same set of actions.
%
Since the actions are the same, all MPI ranks create and execute the same graph,
meaning
that all flow filters execute on all ranks.
%
Filters are free to use MPI and anyway they see fit, including
creating asynchronous tasks.

\paragraph{Shared-Memory Parallelism}
Ascent's main components use portable performance abstraction layers to
take advantage of the different types of shared-memory parallelism on
modern supercomputers.
%
For example, VTK-m is itself a portable performance layer designed specifically
for visualization and currently supports OpenMP, CUDA, and TBB.
%
Devil Ray, while not itself a portable performance layer, uses RAJA to execute
on different architectures, supporting OpenMP, CUDA, HIP, and TBB.

\subsection{Components built into the runtime}
Dray, python, vtkm, ADIOS, Jupyter,

\subsubsection{Data Set Representations}
Ascent uses a data abstraction, called the data object, as the input
and outputs of filters.
%
The data object is responsible for transforming data from one format
to another without unnecessary copies.
%
By using this abstraction, filters can ask for whatever data set
representation they need, however, the converions between data
representations is not always one-to-one.
%

To support multiple data set representations, there must be a common
set of supported features, but not all data models Ascent uses
supports the same set of features.
%
Since Ascent uses Blueprint as its data interface to simulations,
all other data models must sometimes be adapted to support additional
features.
%
For example, Blueprint supports multiple topologies in the same data set
but VTK-m only supports a single topology.
%
To handle this correctly within Ascent, we wrap the data sets in a container
that treats each topology as individual VTK-m data sets.
%

\subsection{Extracts: optional python environment}
I feel like this subsection is about the ways to get to other things.
